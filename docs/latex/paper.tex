\documentclass{article}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables
\usepackage{hyperref}
\newcommand{\theHalgorithm}{\arabic{algorithm}}
\usepackage[accepted]{mlsys2024}

\mlsystitlerunning{Step-by-Step: Training IMU-based Gestures with Live Feedback}

\begin{document}
\twocolumn[
\mlsystitle{Step-by-Step: Training IMU-based Gestures with Live Feedback}

\begin{mlsysauthorlist}
\mlsysauthor{Michael Schnebly}{h}
\end{mlsysauthorlist}

\mlsysaffiliation{h}{School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA}
\mlsyscorrespondingauthor{Michael Schnebly}{michael\_schnebly@g.harvard.edu}

\mlsyskeywords{Machine Learning, MLSys}

\vskip 0.3in

\begin{abstract}
Recognizing user-defined gestures in inertial measurement unit (IMU) data unlocks new forms of creativity and accessibility in human-computer interaction. However, training gesture recognition models is a difficult task that requires a deep understanding of machine learning. We present Step-by-Step, a software tool that allows users to train gesture recognition models with live audiovisual feedback. Step-by-Step uses a simple neural network to learn to recognize and distinguish multiple gestures in IMU timeseries data. Users can train the model by performing gestures and receiving live feedback on the model's performance. Step-by-Step is designed to be accessible to users with no machine learning experience, while providing a powerful codebase for advanced users.
\end{abstract}
]

\printAffiliationsAndNotice{}



\section{Introduction}

\section{Background}

\section{Method}

\section{Findings}

\bibliography{example_paper}
\bibliographystyle{mlsys2024}


\end{document}